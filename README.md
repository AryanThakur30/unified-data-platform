# Unified Data Platform

An end-to-end data ingestion platform that demonstrates how raw data can be ingested, processed, and stored in a centralized KPI data mart using **Python, Docker, and PostgreSQL**.

This project simulates a real-world data engineering workflow including containerized infrastructure, chunk-based ingestion, audit logging, and clean version control practices.

---

## ğŸš€ Key Features

- Chunk-based CSV ingestion using Python and Pandas
- Centralized KPI data mart in PostgreSQL
- Dockerized infrastructure using Docker Compose
- Ingestion audit logging for traceability
- Clean repository structure and Git hygiene
- Production-style workflow suitable for scaling

---

## ğŸ—ï¸ Architecture Overview

CSV File
â”‚
â–¼
Python Ingestion Service
â”‚ (chunk-based processing)
â–¼
PostgreSQL (Docker Container)
â”‚
â”œâ”€â”€ service_costs â†’ KPI Data Mart
â””â”€â”€ ingestion_logs â†’ Audit & Monitoring
---

## ğŸ“‚ Project Structure

unified-data-platform/
â”‚
â”œâ”€â”€ ingestion_service/
â”‚ â”œâ”€â”€ main.py # Ingestion entry point
â”‚ â”œâ”€â”€ processor.py # Chunk-based ingestion logic
â”‚ â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ database/
â”‚ â””â”€â”€ schema.sql # PostgreSQL schema
â”‚
â”œâ”€â”€ docker-compose.yml # Dockerized PostgreSQL setup
â”œâ”€â”€ sample_data.csv # Sample cost data
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
---

## âš™ï¸ How to Run Locally

### 1ï¸âƒ£ Prerequisites
- Docker Desktop
- Python 3.10+
- Git

---

### 2ï¸âƒ£ Start PostgreSQL using Docker

```bash
docker compose up -d
Verify:

docker ps
3ï¸âƒ£ Install Python Dependencies
pip install -r ingestion_service/requirements.txt

4ï¸âƒ£ Run the Ingestion Pipeline
python ingestion_service/main.py

5ï¸âƒ£ Verify Data in PostgreSQL
docker exec -it kpi_postgres psql -U postgres -d kpidb

SELECT * FROM service_costs;
SELECT * FROM ingestion_logs;


This proves **reproducibility**.

---

### 3ï¸âƒ£ Why Chunk-Based Ingestion 

## ğŸ§  Why Chunk-Based Ingestion?

- Prevents memory overload for large files
- Enables scalable backfilling
- Mirrors real production ingestion patterns
- Easy to extend with retries and parallelism
### API Example

GET /kpi/service-costs

Returns live KPI data from PostgreSQL:

```json
[
  {
    "service_name": "payments",
    "cost": 1200.5,
    "cost_date": "2025-12-28"
  }
]
### KPI Summary API

GET /kpi/summary

Returns aggregated cost per service using SQL GROUP BY:

```json
[
  {
    "service_name": "payments",
    "total_cost": 2180.5
  },
  {
    "service_name": "search",
    "total_cost": 961.0
  }
]





